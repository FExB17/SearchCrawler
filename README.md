# ğŸ” SearchCrawler

Ein einfacher Webcrawler in Go, der Ã¼ber DuckDuckGo nach einem Begriff sucht, die gefundenen Webseiten besucht, deren Titel extrahiert und alle Ergebnisse als JSON-Datei speichert.

---

## ğŸ“¦ Features

- Suchbegriff Ã¼ber DuckDuckGo
- Besuch der gefundenen Webseiten
- Titel-Extraktion (HTML `<title>`)
- JSON-Ausgabe: `url` + optional `title`
- Ergebnisse werden in Besuchsreihenfolge gespeichert
- Bestehende `results.json` wird immer Ã¼berschrieben

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ main.go           # Einstiegspunkt, ruft Suche & Crawler auf
â”œâ”€â”€ search.go         # DuckDuckGo-Suche + Link-Parsing
â”œâ”€â”€ crawler.go        # Besucht Seiten & extrahiert Titel
â”œâ”€â”€ results.json      # JSON-Ausgabe (automatisch erstellt)
â”œâ”€â”€ go.mod / go.sum   # AbhÃ¤ngigkeiten (Colly etc.)
```

---

## â–¶ï¸ Verwendung

```bash
go run main.go "schuhe"
```

Das Programm sucht bei DuckDuckGo nach dem Begriff `schuhe`, besucht jede relevante Seite und speichert die Ergebnisse in `results.json`.

---

## ğŸ“„ Beispielausgabe (`results.json`)

```json
[
  {
    "url": "https://www.otto.de/schuhe/",
    "title": "Schuhe online kaufen | OTTO"
  },
  {
    "url": "https://www.eschuhe.de/"
  }
]
```

Hinweis: Wenn der Titel nicht extrahiert werden kann, erscheint nur die URL.

---

## ğŸ”§ NÃ¤chste Schritte (To Do)

- [ ] Webhook-Benachrichtigung (Discord, GitHub Webhooks)
- [ ] Fehler besser handhaben & anzeigen
- [ ] Bot-Tarnung (User-Agent, VerzÃ¶gerungen)

---

## ğŸ“š Technologien

- [Go](https://golang.org/)
- [Colly](https://github.com/gocolly/colly) â€“ Web Scraping Framework

---

## ğŸ§  Gelernt beim Projekt

- Web-Scraping mit Colly
- JSON-Serialisierung in Go
- Umgang mit Structs, Maps, Slices und Pointern
- URL-Encoding & DuckDuckGo-Redirects verstehen

---

## ğŸ‘¨â€ğŸ’» Autor

Furkan â€“ Projekt zum Lernen von Go & Webscraping  
